# A.T.H.E.N.A.

**Augmented Thinking, Heuristic Evaluation & Navigation AI**

---

## ⚠️ Work in Progress

This project is currently under active development and experimentation. For detailed research, experiments, and implementation work, please visit the **[research branch](https://github.com/IMINABO1/A.T.H.E.N.A./tree/research)**.

---

## Overview

Athena is a device-integrated AI assistant that automates cross-application workflows using real-time screen vision, LLM-based intent parsing, voice recognition, and native UI extraction across platforms. ATHENA "sees" your screen, "hears" commands, and interacts with applications via UI tree queries when possible.

## Technologies & Tools

This project leverages cutting-edge AI and automation technologies:

- **[Magma-8B](https://huggingface.co/microsoft/Magma-8B)** - Microsoft's vision-language model for multimodal understanding
- **UI Automation** - Native UI element extraction and interaction using `uiautomation` library
- **PyAutoGUI** - Cross-platform GUI automation for fallback interactions
- **LLM Integration** - Intent parsing and decision-making capabilities

## Platform Support

**Current Focus:** Windows

**Planned Expansion:**
- MacOS
- Android
- iOS
- Other desktop and mobile platforms

## Research & Development

All experimental code, research notes, and development work can be found in the **[research branch](https://github.com/IMINABO1/A.T.H.E.N.A./tree/research)**. This includes:

- UI tree inspection tools
- Screen parsing experiments
- Magma model integration tests
- Cross-application automation prototypes

---

## License

TBD

## Contributing

This is currently a research project. Contributions and feedback are welcome as the project evolves.

